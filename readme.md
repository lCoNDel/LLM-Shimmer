## **Wiki: Desarrollo de Asistentes con LLMs**  
*(Gu√≠a pr√°ctica para aprendizaje y desarrollo con modelos de lenguaje)*  

---

## **üìö Fundamentos Conceptuales**  
*Base te√≥rica esencial para entender el ecosistema LLM*

### 1. **Arquitecturas Clave**  
- **Transformers**: Mecanismos de atenci√≥n y tokenizaci√≥n (BPE vs WordPiece)  
- **Tipos de Modelos**:  
  - *Encoder-only* (BERT, RoBERTa) - Para comprensi√≥n  
  - *Decoder-only* (GPT, LLaMA) - Para generaci√≥n  
  - *Encoder-Decoder* (T5, BART) - Para transformaci√≥n  

### 2. **Tecnolog√≠as Centrales**  
- **Prompt Engineering**:  
  - T√©cnicas: Chain-of-Thought, Few-Shot Learning  
  - Herramientas: LangChain, Semantic Kernel  
- **RAG (Retrieval-Augmented Generation)**:  
  - Implementaci√≥n con ChromaDB/FAISS  
  - Optimizaci√≥n de embeddings con SentenceTransformers  

---

## **üõ† Recursos T√©cnicos**  
*Herramientas y documentaci√≥n para desarrollo pr√°ctico*

### **OpenAI Ecosystem**  
| Recurso | Descripci√≥n | Enlace |  
|---------|-------------|--------|  
| API Oficial | Documentaci√≥n Open AI | [Documentaci√≥n](https://platform.openai.com/docs) |  
| OpenAI Python | Biblioteca oficial | [openai-python GitHub](https://github.com/openai/openai-python) |  
| Cookbook | Ejemplos pr√°cticos | [Open AI CookBook](https://github.com/openai/openai-cookbook) |  

### **Python para LLMs**  
- **Bases**:  
  - [Curso Automate the Boring Stuff](https://automatetheboringstuff.com/) (Fundamentos)  
  - [AsyncIO Docs](https://docs.python.org/3/library/asyncio.html) (Para APIs as√≠ncronas)  
- **Librer√≠as Esenciales**:  
  - Transformers (HuggingFace)  
  - LlamaIndex (Para RAG)  
  - Pydantic (Validaci√≥n de datos)  

---

## **Modelos Open-Source y Comerciales**  
*Comparativa t√©cnica de modelos gratuitos y comerciales*

### **√Årbol Comparativo de Modelos LLM** [^](#comparative-tree)
Principales arquitecturas y sus caracter√≠sticas (2025):

```mermaid
graph TD
    A[Modelos LLM] --> B[Open-Source]
    A --> C[Comerciales]
    
    B --> D[Generalistas]
    B --> E[Especializados]
    C --> F[GPT-O1]
    C --> G[GPT-O3]
    C --> H[Gemini 2.0 Flash]
    
    D --> I[Qwen 2.5 Max<br>Arquitectura MoE<br>20T tokens]
    D --> J[DeepSeek R1<br>Razonamiento avanzado<br>671B params]
    D --> K[Llama3.1-405B<br>Dense<br>128K contexto]
    D --> L[DeepSeek-V3<br>Arquitectura MoE<br>671B params]
    D --> M[Qwen2.5-72B<br>Rendimiento c√≥digo/matem√°ticas]
    
    E --> N[DeepSeek-Coder-33B<br>Generaci√≥n de c√≥digo]
    E --> O[Qwen-VL-72B<br>Multimodal]
    E --> P[DeepSeekMath-7B<br>Razonamiento avanzado]
    
    style I fill:#FFE4E1,stroke:#333
    style J fill:#E0FFFF,stroke:#333
    style K fill:#F0FFF0,stroke:#333
    style L fill:#FFFACD,stroke:#333
    style M fill:#E6E6FA,stroke:#333
```

### **Tabla Comparativa Detallada** [^](#detailed-table)
| Modelo | Arquitectura | Par√°metros | Fortalezas | Licencia | Casos de Uso |
|--------|--------------|------------|------------|----------|--------------|
| **Qwen 2.5 Max** | MoE | 20T tokens | Multimodal, l√≠der en MMLU-Pro y LiveCodeBench | Apache 2.0 | Desarrollo software, RAG |
| **DeepSeek R1** | Dense | 671B | Razonamiento avanzado, l√≠der en GPQA-Diamond | Apache 2.0 | Investigaci√≥n, an√°lisis complejo |
| **GPT-O1** | H√≠brida | - | Optimizado para tareas espec√≠ficas | Comercial | Aplicaciones globales |
| **GPT-O3** | H√≠brida | - | Mejor rendimiento en tareas generales | Comercial | Asistentes conversacionales |
| **Gemini 2.0 Flash** | Dense | - | Multimodal, r√°pido y eficiente | Comercial | An√°lisis de datos, generaci√≥n de contenido |
| **DeepSeek-V3** | MoE | 671B | Eficiencia en recursos, l√≠der en MMLU (89.1%)  | Apache 2.0 | Educaci√≥n, an√°lisis financiero |
| **Qwen2.5-72B** | Dense | 72B | SOTA en c√≥digo (HumanEval 85+)  | Apache 2.0 | Desarrollo software, RAG |
| **Llama3.1-405B** | Dense | 405B | Mayor modelo open-source  | Meta License | Investigaci√≥n, prototipado |
| **DeepSeek-Coder** | MoE | 33B | Soporte 16K tokens en c√≥digo  | Apache 2.0 | DevOps, IDE inteligentes |

Nota: Todas las licencias Apache 2.0 y Meta License est√° disponibles para uso p√∫blico.

---

## **‚öñÔ∏è √âtica y Buenas Pr√°cticas**  
*Gu√≠a para desarrollo responsable*

### **Checklist Obligatorio**  
- [ ] Verificar licencia del modelo base  
- [ ] Implementar filtros de contenido sensible  
- [ ] Auditor√≠a de sesgos con BiasBench  
- [ ] Documentar fuentes de entrenamiento  

### **Recursos Legales**  
- [Model License Database](https://huggingface.co/spaces/mlaw-ai/llm-license-checker)   

---

## **üìÇ Estructura de Proyecto Recomendada**  
*(Para repositorios GitHub)*  
```
/llm-project
  ‚îú‚îÄ‚îÄ /notebooks       # Jupyter notebooks educativos
  ‚îú‚îÄ‚îÄ /src             # C√≥digo de producci√≥n
  ‚îÇ    ‚îú‚îÄ‚îÄ rag_system  # Componentes RAG
  ‚îÇ    ‚îî‚îÄ‚îÄ api         # Endpoints FastAPI
  ‚îú‚îÄ‚îÄ /docs            # Documentaci√≥n t√©cnica
  ‚îú‚îÄ‚îÄ .github          # CI/CD y templates
  ‚îî‚îÄ‚îÄ ethical_audit.md # Reporte de cumplimiento
```

---

### **Proyectos y Repositorios**  
- **GitHub Pages**: Publicaci√≥n de webs en GitHub  
  [GitHub Pages Repo](https://github.com/skills/github-pages)  
- **Crawl4AI**: Rastreos web con IA  
  [Crawl4AI Repo](https://github.com/unclecode/crawl4ai)  
- **Agent Embed**: Integraci√≥n de agentes conversacionales  
  [Agent Embed Repo](https://github.com/Predictable-Dialogs/agent-embed)  
- **Open Assistant GPT**: Asistentes conversacionales en cloud  
  [Open Assistant GPT Repo](https://github.com/OpenAssistantGPT/OpenAssistantGPT)  

---
